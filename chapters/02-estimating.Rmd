# Estimating and reporting {#reporting}

This chapter uses a large number of packages, and the SAFI data 
set, so make sure
all are downloaded by running the code from the [Set-up section](#setup).

I will create a table of descriptive statistics, and a simple regression
table.

## Generating some fake data

First we make a fake intervention aimed at improving fertilizer adoption.
Adoption depends on the treatment and education and a random component.
The page on [DeclareDesign](#declaredesign) has more advanced techniques
to generate fake data.

```{r}

library(tidyverse)
library(here)
library(modelsummary)
library(flextable)
library(estimatr)
library(lmtest)
library(clubSandwich)

rm(list=ls())
set.seed(1)

data <-  
  read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
  left_join({.} %>%
            select(village) %>%
            distinct(village) %>%
            rowwise %>%
            mutate(treatment = rbinom(1,1,0.5)))%>%
  rowwise() %>%
  mutate(educated = rbinom(1,1,0.3),
         u = sample(c(0.1,0.2,0.3),1),
         prob = 0.3 * treatment + 0.1 * educated + u,
         uses_fertilizer = rbinom(1,1,prob)) %>%
  ungroup() %>%
  select(-prob,-u) 

```


## Making a table of summary statistics

### Using modelsummary and flextable

The `modelsummary` package is the most convenient to create tables. To convert them
to word, I use the `flextable` package.

For a simple table of descriptive statistics, use the `datasummary()` function. I also
define a vector with variable labels, which I use throughout this chapter. Below, I use
it in the `labelizor()` function, which applies labels to a flextable object. I also 
apply the `autofit()` and `fix_border_issues()` functions to make the table look nicer.


```{r}

library(modelsummary)
library(flextable)

# vector for labelling variable names
labels = c(no_membrs = "# HH Members",
           years_liv = "Year in village",
           rooms = "# Rooms",
           liv_count = "# Livestock",
           no_meals = "# Meals",
           treatment = "Treated",
           educated = "Educated",
           uses_fertilizer = "Uses fertilizer",
           `(Intercept)` = "Constant")

# descriptive stats
data %>%
  select(where(is.numeric), -ends_with("ID")) %>%
  datasummary(All(.) ~ Mean + SD + min + max + Histogram , data = ., output = "flextable") %>%
  labelizor(j =1,labels = labels, part = "all")%>% 
  fix_border_issues() %>% 
  autofit()

```

Flextables can be easily exported to Word using the `save_as_docx()` function.


### Balance Table

Using `modelsummary`'s `datasummary_balance()` table function, it is easy
to create a balance table:

```{r}

treat_labels <- c("0" = "Control", "1" = "Treated")

# balance table
data %>%
  select(where(is.numeric), -ends_with("ID")) %>%
  datasummary_balance( ~ treatment , data = ., 
                      output = "flextable", stars = TRUE, 
                      dinm = TRUE, dinm_statistic = "p.value") %>%
  labelizor(j =1,labels = labels, part = "all")%>%
  labelizor(labels = treat_labels, part = "header")%>% 
  fix_border_issues() %>% 
  autofit()

```

### Advanced: Using only Flextable

For more control, the flextable package can convert data frames into good-looking tables using the 
`tabulator()` function.

First, make a data frame with summary statistics. 
I duplicate the data set using `bind_rows()` to create an overall group. 
Then I use 
[`summarize(across(...))`](https://dplyr.tidyverse.org/reference/across.html)
to apply summarizing functionsto a number of variables. 

```{r}

summstats <-
  bind_rows(data %>% 
              mutate(Treatment = ifelse(treatment,
                                        " Treatment",
                                        "  Control")),
            data %>% 
              mutate(Treatment = "Overall")) %>% 
  mutate(Treatment = factor(Treatment)) %>%
  select(where(is.numeric),Treatment,-key_ID,-treatment) %>%
  group_by(Treatment) %>%
  summarize(across(.cols = everything(),
                   .fns = list(n =  ~sum(!is.na(.x)),
                               nmiss =  ~sum(is.na(.x)),
                               mean = ~mean(.x,na.rm=TRUE),
                               sd = ~sd(.x,na.rm=TRUE),
                               min =  ~min(.x,na.rm=TRUE),
                               max =  ~max(.x,na.rm=TRUE),
                               iqr =  ~IQR(.x,na.rm=TRUE)),
                      .names =  "{.col}-{.fn}")) %>%
  pivot_longer(cols = -Treatment,
                 names_to = c("Variable",".value"),
                 names_sep="-") 



summstats




```


Then use I flextable's `tabulator()` to make output that looks good in word. 
Note that `tabulator()` sorts the columns alphabetically, 
so that would be `control - overall - treatment`. 
That doesn't make sense, 
so I have used spaces (`" Treatment"`) to control the ordering. 

I've added a bunch of statistics to show the flexibility:

```{r}

library(flextable)

summstats %>%
  tabulator(rows = "Variable",
          columns = "Treatment",
          `N` = as_paragraph(as_chunk(n,digits=0)),
          `Mean (SD)` =  as_paragraph(as_chunk(fmt_avg_dev(mean, 
                                      sd, digit1=2,digit2 = 2))),
          Range = as_paragraph(as_chunk(min,digits=3), "-",as_chunk(max,digits=3)) ) %>%
  as_flextable()


```

To add a column with differences, I first define a 
[function](#functions) to compute the differences (I use a regression 
rather than a ttest, so I can cluster my standard errors etc. to this if
I need to). 
Then I use 
[`summarize(across(...))`](https://dplyr.tidyverse.org/reference/across.html) 
in much the same way as above, now to create a dataframe called `difcol`. 

```{r}

library(estimatr)

get_diffs <- function(equation, clusters = NULL, weights = NULL, std.error = FALSE){

  reg <-  
    lm_robust(equation, clusters = {{ clusters }}, weights = {{ weights }}) %>% 
    broom::tidy()

  estimate <- round(reg[2,2],2)

  p <- reg[2,5]

  stars = case_when(p < 0.001 ~ "***",
                    p < 0.01 ~ "**",
                    p < 0.05 ~ "*",
                    .default = "" )

    paste0(estimate,stars)
  
}

difcol <-
  data %>%
  select(where(is.numeric),-key_ID,treatment,village) %>%
  summarize(across(.cols = c(everything(), -treatment, -village),
                   .fns = ~get_diffs(.x ~ treatment, clusters = village))) %>% 
  pivot_longer(cols =everything(),
               names_to = "Variable",
               values_to="Difference")  



```

Then, all I have to do is add it to `tabulator()` using its `datasup_last` 
argument. Below, I also use a few other flextable function to make the 
table nicer. In particular, `labelizor()` to add variable
labels, for which I use the named vector I defined above.

```{r}

descriptive_table_flex <-
  summstats %>%
  tabulator(rows = "Variable",
            columns = "Treatment",
            datasup_last = difcol,
            `N` = as_paragraph(as_chunk(n,digits=0)),
            `Mean (SD)` =  as_paragraph(as_chunk(fmt_avg_dev(mean, sd, digit1=2,digit2 = 2)))) %>%
  as_flextable()  %>%
  labelizor(j = "Variable", labels = labels, part = "body") %>% 
  fix_border_issues() %>% 
  autofit()

descriptive_table_flex

```

Again, to save it as a word file, use
`save_as_docx(path = "my/file.docx")`.


## Simple regression

A simple regression uses the `lm()` function. I use the `modelsummary()`
function to display it:

```{r }

lm <- lm(uses_fertilizer ~ treatment + educated, data = data)
modelsummary(lm, output = "flextable")


```

## Robust standard errors

To get robust standard errors clustered at the village
level, using the same procedures Stata uses, I use  
[`lm_robust()`](https://declaredesign.org/r/estimatr/reference/lm_robust.html):

```{r }

library(estimatr)
lmrobust <-
  lm_robust(uses_fertilizer ~ treatment + educated, 
            data = data, clusters = village, se_type = "CR2")


modelsummary(list("LM" = lm, "Robust" = lmrobust), output = "flextable")

```


I'd like to have just the N, r-squared and Adjusted R-squared:

```{r }


modelsummary(list("LM" = lm, "Robust" = lmrobust), 
             gof_map = c("nobs","r.squared","adj.r.squared"),
             output = "flextable")


```

If you want to add the number of clusters, you will need to do some
work. `modelsummary()` gets the N etc. from the 
[`broom::glance()`](https://declaredesign.org/r/estimatr/reference/estimatr_glancers.html)
function. For `lm_robust()` models, this doesn't report the number of 
clusters.
However, you can make sure that it does, by making a custom 
glance methods for lm_robust objects (see 
[here](https://modelsummary.com/articles/modelsummary.html) 
for details on how to make use custom glance methods in modelsumary):

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

glance_custom.lm_robust <- function(x) {
  # this function takes glance() output, and adds a nclusters column
  glance(x) %>%
  mutate(nclusters = x$nclusters)
}

modelsummary(list("LM" = lm, "Robust" = lmrobust), 
             gof_map = c("nobs","r.squared","adj.r.squared", "nclusters"),
             output = "flextable")


```

Now lets add  a probit model!

```{r }

probit <- glm(uses_fertilizer ~ treatment + educated, 
                family = binomial(link = "probit"), 
                data = data)

modelsummary(list("LM" = lm, "Robust" = lmrobust, "Probit"  = probit), 
             gof_map = c("nobs","r.squared","adj.r.squared", "nclusters"),
             output = "flextable")


```


Adding cluster-robust standard errors to the probit model is a bit more 
complex. There is no `glm_robust()` function. 
You can estimate a probit model, 
then use `coeftest()` to get clustered standard errors, 
and then use the `glance_custom ` method to add the number of clusters to that. 

However, 
you can create your own `glm_robust` function, 
~~with blackjack and hookers~~
including `tidy()` and `glance()` methods that return everything
you want to `modelsummary()`.
I use `vcovCR` from the `clubSandwich` package to compute `CR2` standard errors,
which are the default in `estimatr`,
so everything is nice and consistent with the linear probability model.


```{r}

# this function estimates a probit model, and 
# then computes the cluster-robust standad errors using
# clubSandwich and coeftest
# it returns a glm_robust object, which is just a modified 
# coeftest object
glm_robust <- function(formula,family,data,cluster, type = "CR2") {
  library(lmtest)
  library(clubSandwich)
 
  probit <- 
    glm(formula, 
        family = family, 
        data = data)

  model <-
    probit%>%
    coeftest(.,
             vcovCR({.}, 
                    cluster = data[[cluster]], 
                    type = type), 
              save = TRUE) 


  # this computes the number of unique clusters in the data used
  # for the original mode
  attr(model,"nclusters") <- 
    data[row.names(model.frame(probit)),cluster] %>% unique() %>% nrow()

  class(model) <- "glm_robust"
  model
}

# this is the custom tidy methods for glm_robust objects
# it returns a dataframe with coefficients
tidy.glm_robust <- function(x, ...){
  x[,] %>% as_tibble() %>%
  mutate(term = attr(x,"dimnames")[[1]]) %>%
  select(term,
         estimate = Estimate,
         std.error = `Std. Error`,
         statistic = `z value`,
         p.value = `Pr(>|z|)`) 
}


# this is the glance method. It returns a data frame with 
# the number of obserations, log likelihood and number of clusters
glance.glm_robust <- function(x, ...){
  tibble(nobs = attr(x,"nobs"),
         logLik = as.numeric(attr(x,"logLik")),
        nclusters = attr(x,"nclusters")
        )
}


```

You can then simply use the `glm_robust()` function and `modelsummary()`
will know how to handle its output!

```{r, warning = FALSE}

probitrobust <- 
  glm_robust(uses_fertilizer ~ treatment + educated, 
             family = binomial(link = "probit"), 
             data = data, cluster="village", type = "CR2")

modelsummary(list("LM" = lm, "LM Robust" = lmrobust, 
                  "Probit"  = probit, "Probit Robust" = probitrobust), 
             gof_map = c("nobs","r.squared","adj.r.squared", "nclusters"),
             coef_map = labels,
             stars = TRUE,
             output = "flextable") %>%
  autofit()




```