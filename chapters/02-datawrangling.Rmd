# Data Wrangling {#datawrangling}

Make sure you have the `tidyverse` installed, and the SAFI data set
downloaded to your data folder by running the code from the [Set-up section](#setup)

## Basic Data Manipulation

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

library(tidyverse)
library(here)

read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
    filter(village == "Chirodzo") %>%
    mutate(people_per_room = no_membrs / rooms,
           day = day(interview_date),
           month = month(interview_date),
           year = year(interview_date)) %>%
    select(key_ID:rooms, day:people_per_room, -village) %>%
    filter(interview_date > "2016-12-1" & interview_date < '2017-01-01')

```

## Pivoting (or reshaping)

In tidyverse, reshaping is called pivoting. Here's how you 
pivot a household roster (reshape wider) so you can merge 
it with the household data.


### Creating fake data

First, I create sa fake household roster, based on the SAFI data,
making sure that the household roster has a number of lines
for each household that is equal to the household size, and has two
randomly generated variables: `female` and `age`.

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

long_data <- 
    read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
    select(key_ID,no_membrs ) %>%
    uncount(no_membrs) %>%
    group_by(key_ID) %>% 
    mutate(member_ID = row_number()) %>%
    rowwise() %>%
    mutate(female = sample(0:1,1),
           age = case_when(member_ID == 1 ~ sample(18:86,1),
                          .default = sample(0:86,1))) %>%
    ungroup()

long_data

```

### Pivoting long to wide

To merge this into our main data set, we need to make sure we go back to having 1 observation per household. We will do this by using `pivot_wider()`:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

wide_data <-
    long_data %>% 
    pivot_wider(names_from = member_ID,
                values_from = !ends_with("_ID"))
wide_data

```

We only needed to specify two options:

- names_from: this is the column that contains the names (or usually numbers)
for each of our units of analysis. In this case, the `member_ID`.
- values_from: the variables containing the data. All variables you specify here, will get one column for each possible value of names_from. In our case, these variables `female` and `age`. I used [tidy select syntax](https://tidyr.tidyverse.org/reference/tidyr_tidy_select.html) to specify all variables except the ones ending in "\_ID". 



### Pivoting wide to long

If we had started with wide data, and had wanted to transform to
long data, we'd have to use `pivot_longer()`:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

recreated_long_data <-
    wide_data %>%
    pivot_longer(!key_ID, 
                 names_to = c(".value", "member_ID"),
                 names_sep="_",
                 values_drop_na = TRUE)
long_data

```

In this case, the syntax is a bit harder to understand than that of pivot wider. It's good to think first what the original data looks like, and 
how I intend to transform it. The wide data has columns key_ID, age_1-19 and female_1-19. I don't really want to touch the key_ID
column. I want to turn the columns age_1-19 and female_1-19 into three columns: female, age and Member_ID, which contains the values 1-19. This translates to the options we passed to `pivot_longer()` as follows:

- `!key_ID`: We want to pivot the data that's in all columns except key_ID. 
- `names_to = c(".value", "member_ID")`: this specifies the new columns we want to create. It basically says that the existing column names consist of two parts: one part (i.e. female and age) that we wish to keep as column names , and one part (i.e. the numbers 1-19) which should be put into a new column which we will "member_ID".
- `"names_sep="`: this indicates how the two parts mentioned above are 
separated. If there is no separator (for example your variables are called age1, age2, etc.) you'll have to use the`names_pattern` option.
- `values_drop_na = TRUE`: tells R to drop rows that have missing data for 
all variables. If we had set this to FALSE, we'd have 19 rows for each
household, with a lot of missing data in all households smaller than 19 people.

## Joining (or merging) data

Tidyverse has four functions to join (or merge, as Stata calls it) two
data sets. The functions that differ in the way they treat observations that are in one data set but not the other. 
Consider the diagram below. 
It has two data sets, `x` (in Stata terms, this is the master data set) and `y` (the using 
data set in Stata terms). They have overlapping rows (area B), but also
rows that are only in `x` (area A) or only in `y` (area C).

![](images/join_venn.png)

The four join functions work as follows:

- `inner_join()` will only keep area B.
- `left_join()` will keep areas A and B.
- `right_join()` will keep areas B and C.
- `full_join()` will keep areas A, B, and C.

In our case, the data sets match perfectly, i.e. we only have an area B, so there is no practical difference. I chose `left_join()` so the number of 
observations in my household survey is guaranteed to remain the same.
To merge the roster to the household data, we use the join_by function:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=TRUE}

read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
    left_join(wide_data)

```

Note that we didn't specify identifiers, like we would in Stata. R 
assumed that the variables that appear in both data frames are the 
identifiers, in this case `key_ID`. Use the `by` option to change this.

Going the other way around, joining the household data to the 
roster data, is equally easy:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=TRUE}

long_data %>%
    left_join(
        read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>% 
            select(key_ID,village,interview_date))
```
Note that here I only merged in two variables, by using `select` and a pipe within the `left_join()` function.

## Summarizing over groups (or collapsing data)

To compute summary statistics (sums, counts, means etc.) over a group,
we use the `group_by()` and `summarize()` functions. For example, to
compute the household size, number of women and average age in each household:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=TRUE}

long_data %>%
    group_by(key_ID) %>%
    summarize(hh_size = n(), num_women = sum(female), mean_age = mean(age))    
```


## Row-wise Operations

Suppose we wanted to run an operation over multiple variables. For example to
get the household size, number of women and average age. The easiest,
and probably best, way to do this in R is by reshaping to long, and the use
summarize, like we did above. But in Stata you would probably use some sort of 
`egen` function, so that may come natural.
You can do similar things in R. It's just a bit more complex than in Stata:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=TRUE}

wide_data %>%
    rowwise() %>%
    mutate(mean_age = mean(c_across(starts_with("age_")),
                           na.rm=TRUE),
           num_women = sum(c_across(starts_with("female_")),
                           na.rm=TRUE),
           hh_size = sum(!is.na(c_across(starts_with("female_"))),
                         na.rm=TRUE)) %>%
    select(key_ID,hh_size,num_women,mean_age) %>%
    ungroup()


```

The key trick here is the combination of `rowwise()` and `c_across()`.
`rowwise()` ensure all summaries are computed per row, and `c_across()`
allows you to use [tidy select](https://dplyr.tidyverse.org/reference/dplyr_tidy_select.html) syntax within the `mean()` and `sum()` functions.
`sum(!is.na())` simply counts the non-missing values.

## Splitting multi-response variable into dummies

The SAFI data contains a number of columns that contain all responses selected
in a multiple response questions. For example, the variables `items_owned` can
contain something like `"bicycle;television;solar_panel;table"`. We want to 
split this into dummies: one for each possible answers. There's a number of 
ways to do this: 

First, you can use `str_count()` for each possible answer: 

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

split_without_loop <- 
    read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
    select(items_owned) %>%
    mutate(owns_bicycle = str_count(.data$items_owned,"bicycle"), 
           owns_television = str_count(.data$items_owned,"television")) 
           #etc etc.

split_without_loop

```

### Using loops

This gets extremely tedious, better to put everything in a loop:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

#define the vector to loop over
items <- c("bicycle","television","solar_panel","table","cow_cart","radio",
           "cow_plough","solar_torch","mobile_phone","motor_cycle","fridge",
           "electricity","sofa_set","lorry","sterio","computer","car")

#prepare the data
split_with_loop <- 
    read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
    select(items_owned)

#and add to the data each iteration of a loop
for (i in items){
    split_with_loop <-
        split_with_loop %>%
        mutate("owns_{i}" := str_count(.data$items_owned,i))
}

split_with_loop

```

Note how we used `"owns_{i}" :=` to dynamically create variable names in the `mutate()` function.


### Using map() and pmap()

Loops have the reputation of being slow, so if performance is important
you can also use 
`map()` to repeat a function for every element in a vector. It returns a list
where each list item is the output of one iteration (i.e. one new column):

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

split_with_map <- 
    read_csv(here("data/SAFI_clean.csv"), na = "NULL")

items %>%
  map(\(x) str_count(split_with_map$items_owned,x))%>%
  head(n = 2)

```

A list isn't really great in this case. `map_df()` returns its 
items as columns in a dataframe. For this
to work, I make sure the vector has names, which will then become
the column names:  


```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

items %>%
  set_names(paste0("owns_",items)) %>%
  map_df(\(x) str_count(split_with_map$items_owned,x)) 

```

One problem is our pipe started with `items`, making it a bit more difficult to
use this is a data management pipeline. To solve this, you can also iterate 
over the rows in a data frame using `pmap()`, so that each element in our 
list is a row:

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
    pmap(\(items_owned, ...) str_count(items_owned,items)) %>%
    head(n = 2)
                            
```

Note that pmap passes all variables in the data frame as arguments to the function. Here,
I only need `items_owned`, so I capture all unneeded variables with `...`.

To bind this together to a data frame, I need to make sure that the output 
of each iteration of `pmap()` is a row with `as_tibble_row()`, using its
`.name_repair` option to assing names in the same way I did to the `items`
vector above.

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}


read_csv(here("data/SAFI_clean.csv"), na = "NULL")  %>%
  pmap_dfr(\(items_owned, ...) 
              str_count(items_owned,items) %>%
              as_tibble_row(.name_repair = ~paste0("owns_",items)))

```

### Using rowwise(), mutate() and unnest()

While `map()` is faster,  you can use `mutate()`
to nest a data set into a variable. That, combined with
 `as_tibble_row()`:

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
  rowwise() %>%
  mutate(x = as_tibble_row(str_count(items_owned,items),
                           .name_repair = ~paste0("owns_",
                                                  items))) %>%
  unnest(cols=c(x))

```

### Using separate_longer()

If writing a vector with possible values is too tedious/error prone/impossible:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
    separate_longer_delim(items_owned, delim = ";") %>%
    mutate(value = 1) %>%
    pivot_wider(names_from = items_owned,
                values_from = value,
                names_glue = "owns_{items_owned}",
                values_fill = 0)

```

Note that this solution differs in how observations where `items_owned` is 
empty are treated. Previous solutions had `NA` for all created variables in this 
case; using this approach, a variable `owns_NA` is created, with value `1`, and
all other variables are set to `0`.
It's unclear which is better in this
case: does an empty `items_owned` means the household owns nothing? Then this 
implementation is better. Does it mean the quesitons was skipped? Then the 
previous ones were better.