# Estimating and reporting {#reporting}

This chapter uses a large number of packages, and the SAFI data 
set, so make sure
all are downloaded by running the code from the [Set-up section](#setup).

I will create a table of descriptive statistics, and a simple regression
table.

## Generating some fake data

First we make a fake intervention aimed at improving fertilizer adoption.
Adoption depends on the treatment and education and a random component.
The page on [DeclareDesign](#declaredesign) has more advanced techniques
to generate fake data.

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=TRUE}

library(tidyverse)
library(here)

rm(list=ls())
set.seed(1)

data <-  
  read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
  left_join({.} %>%
            select(village) %>%
            distinct(village) %>%
            rowwise %>%
            mutate(treatment = rbinom(1,1,0.5)))%>%
  rowwise() %>%
  mutate(educated = rbinom(1,1,0.3),
         u = sample(c(0.1,0.2,0.3),1),
         prob = 0.3 * treatment + 0.1 * educated + u,
         uses_fertilizer = rbinom(1,1,prob)) %>%
  ungroup() %>%
  select(-prob,-u) 

```

## Making a table of summary statistics

### Using modelsummary and flextable

The `modelsummary` package is the most convenient to create tables. To convert them
to word, I use the `flextable` package.

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

library(modelsummary)
library(flextable)

labels = c(no_membrs = "# HH Members",
           years_liv = "Year in village",
           rooms = "# Rooms",
           liv_count = "# Livestock",
           no_meals = "# Meals",
           treatment = "Treated",
           educated = "Educated",
           uses_fertilizer = "Uses fertilizer",
           `(Intercept)` = "Constant")

# descriptive stats
data %>%
  select(where(is.numeric), -ends_with("ID")) %>%
  datasummary(All(.) ~ Mean + SD + min + max + Histogram , data = ., output = "flextable") %>%
  labelizor(j =1,labels = labels, part = "all")%>% 
    fix_border_issues() %>% 
    autofit()

```

Flextables can be easily exported to Word using the `save_as_docx()` function.


### Balance Table

Using `modelsummary`'s `datasummary_balance()` table function, it is easy
to create a balance table:

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

treat_labels <- c("0" = "Control", "1" = "Treated")

# balance table
data %>%
select(where(is.numeric), -ends_with("ID")) %>%
datasummary_balance( ~ treatment , data = ., output = "flextable", start = TRUE, dinm = TRUE, dinm_statistic = "p.value") %>%
labelizor(j =1,labels = labels, part = "all")%>%
labelizor(labels = treat_labels, part = "header")%>% 
  fix_border_issues() %>% 
  autofit()
```

### Advanced: Using only Flextable

For more control, the flextable package can covert data frames into good-looking table using the 
`tabulator()` function.

First, make a data frame with summarry statistics. I duplicate the data set using `bind_rows()`
to create an overall group.

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

summstats <-
bind_rows(data %>% mutate(Treatment = ifelse(treatment," Treatment","  Control")),
          data %>% mutate(Treatment = "Overall")) %>% 
  select(where(is.numeric),Treatment,-key_ID,-treatment) %>%
  group_by(Treatment) %>%
  summarize(across(everything(),
                     list(n =  ~sum(!is.na(.x)),
                          nmiss =  ~sum(is.na(.x)),
                          mean = ~mean(.x,na.rm=TRUE),
                          sd = ~sd(.x,na.rm=TRUE),
                          min =  ~min(.x,na.rm=TRUE),
                          max =  ~max(.x,na.rm=TRUE),
                          iqr =  ~IQR(.x,na.rm=TRUE)),
                      .names =  "{.col}-{.fn}")) %>%
  pivot_longer(cols = -Treatment,
                 names_to = c("Variable",".value"),
                 names_sep="-") 

summstats

```


Then use I flextable's `tabulator()` to make output that looks good in word. 
Note that `tabulator()` sorts the columns alphabetically, so that would be
control, overall, treatment. That doesn't make sense, so I have used spaces (`" Treatment"`) to 
control the ordering. 

I've added a bunch of statistics to show the flexibility:

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

library(flextable)

summstats %>%
tabulator(rows = "Variable",
          columns = "Treatment",
          `N` = as_paragraph(as_chunk(n,digits=0)),
          `Mean (SD)` =  as_paragraph(as_chunk(fmt_avg_dev(mean, sd, digit1=2,digit2 = 2))),
          Range = as_paragraph(as_chunk(min), "-",as_chunk(max)) ) %>%
as_flextable() 


```

To add a column with differences, I first define a [function](#functions) to compute the differences
(I use a regression rather than a ttest, so I can cluster my standard errors etc. to this if I need to). 
Then I use `summarize(across())` in much the same way as above, now to create a dataframe called `difcol`. 
Note that I use `.` to refer to the dataset currently in the `%>%` pipe.

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}


get_diffs <- function(.df,y,x){

  reg <-  lm(y~ x) %>% broom::tidy()

  coeff = round(reg[2,2],2)
  p <- reg[2,5]

  stars = case_when(p < 0.001 ~ "***",
                    p < 0.01 ~ "**",
                    p < 0.05 ~ "*",
                    .default = "" )

  paste0(coeff,stars)
}


difcol <-
  data %>%
  select(where(is.numeric),-key_ID,-treatment) %>%
  summarize(across(everything(),
                   .fns = function(x) get_diffs(.,.$x,data$treatment))) %>%
  pivot_longer(cols =everything(),
               names_to = "Variable",
               values_to="Difference")  


```

Then, all I have to do is add it to `tabulator()` using its `datasup_last` argument. Below, I also
use a few other flextable function to make the table nicer. In particular, `labelizor()` to add variable
labels, which I define as a vector.

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

#named vector with variable labels:
labels <- c("Household members","Years lived","Rooms","N. livestock owned","Meals per day", "Educated","Uses Ferilizer")
names(labels) <- summstats[[2]][1:7]


descriptive_table_flex <-
  summstats %>%
  tabulator(rows = "Variable",
            columns = "Treatment",
            datasup_last = difcol,
            `N` = as_paragraph(as_chunk(n,digits=0)),
            `Mean (SD)` =  as_paragraph(as_chunk(fmt_avg_dev(mean, sd, digit1=2,digit2 = 2)))) %>%
  as_flextable()  %>%
  labelizor(j = "Variable", labels = labels, part = "all") %>% 
  fix_border_issues() %>% 
  autofit()

descriptive_table_flex

```

To save it to word:

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

descriptive_table_flex %>%
  save_as_docx(path = here("tables/summs_stats_flex.docx"))

```


You can find the resulting .docx [here](https://github.com/kleuveld/r_cheatsheet/raw/main/tables/summs_stats_flex.docx).


## Simple regression

A simple regression uses the `lm()` function. I use the `modelsummary()`
function to display it:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

lm <- lm(uses_fertilizer ~ treatment + educated, data = data)
modelsummary(lm, output = "flextable")


```

## Robust standard errors

To get robust standard errors clustered at the village
level, using the same procedures Stata uses, I use the `lm_robust()`
function:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

library(estimatr)
lmrobust <-
  lm_robust(uses_fertilizer ~ treatment + educated, 
            data = data, cluster = village, se_type = "stata")


modelsummary(list("LM" = lm, "Robust" = lmrobust), output = "flextable")

```


I'd like to have just the N, r-squared and Adjusted R-squared:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}


modelsummary(list("LM" = lm, "Robust" = lmrobust), 
             gof_map = c("nobs","r.squared","adj.r.squared"),
             output = "flextable")


```

If you want to add the number of clusters, you will need to do some
work. It gets the N etc. from the `broom::glance()` function. For
`lm_robust()` models, this doesn't report the number of clusters.
However, you can make sure that it does, by making a custom 
glance methods for lm_robust objects (see 
[here](https://modelsummary.com/articles/modelsummary.html) 
for details):

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

glance_custom.lm_robust <- function(x) {
  # this function takes glance() output, and adds a nclusters column
  glance(x) %>%
  mutate(nclusters = x$nclusters)
}

modelsummary(list("LM" = lm, "Robust" = lmrobust), 
             gof_map = c("nobs","r.squared","adj.r.squared", "nclusters"),
             output = "flextable")


```

Now lets add  a probit model!

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

probit <- glm(uses_fertilizer ~ treatment + educated, 
                family = binomial(link = "probit"), 
                data = data)

modelsummary(list("LM" = lm, "Robust" = lmrobust, "Probit"  = probit), 
             gof_map = c("nobs","r.squared","adj.r.squared", "nclusters"),
             output = "flextable")


```


Adding cluster-robust standard errors to the probit model is a bit more complex.
There is no `glm_robust()` function. However, you can create one, including
`tidy()` and `glance()` methods that return the right statistics to `modelsummary()`:


```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=TRUE}


glm_robust <- function(formula,family,data,cluster) {
  library(lmtest)
  library(sandwich)

  probit <- glm(formula, 
               family = family, 
                data = data)
  
  cluster_formula <- as.formula(paste0("~", cluster))

  model <- 
    coeftest(probit, vcov = vcovBS(probit,cluster=cluster_formula))

  class(model) <- "glm_robust"

  attr(model,"nclusters") <- 
    data[row.names(model.frame(probit)),cluster] %>% unique() %>% nrow()

  model
}


tidy.glm_robust <- function(x, ...){
  x[,] %>% as_tibble() %>%
  mutate(term = attr(x,"dimnames")[[1]]) %>%
  select(term,
         estimate = Estimate,
         std.error = `Std. Error`,
         statistic = `z value`,
         p.value = `Pr(>|z|)`) 
}

glance.glm_robust <- function(x, ...){
  tibble(nobs = attr(x,"nobs"),
         logLik = as.numeric(attr(x,"logLik")),
        nclusters = attr(x,"nclusters")
        )
}




probitrobust <- glm_robust(uses_fertilizer ~ treatment + educated, family = binomial(link = "probit"), 
                data = data, cluster="village")


modelsummary(list("LM" = lm, "LM Robust" = lmrobust, "Probit"  = probit, "Probit Robust" = probitrobust), 
             gof_map = c("nobs","r.squared","adj.r.squared", "nclusters"),
             coef_map = labels,
             stars = TRUE,
             output = "flextable") %>%
autofit()

```