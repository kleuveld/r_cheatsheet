# Estimating and reporting {#reporting}

This chapter uses a large number of packages, and the SAFI data 
set, so make sure
all are downloaded by running the code from the [Set-up section](#setup).

I will create a table of descriptive statistics, and a simple regression
table.

## Generating some fake data

First we make a fake intervention aimed at improving fertilizer adoption.
Adoption depends on the treatment and education and a random component.
The page on [DeclareDesign](#declaredesign) has more advanced techniques
to generate fake data.

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=TRUE}

library(tidyverse)
library(here)

rm(list=ls())
set.seed(1)

data <-  
  read_csv(here("data/SAFI_clean.csv"), na = "NULL") %>%
  left_join({.} %>%
            select(village) %>%
            distinct(village) %>%
            rowwise %>%
            mutate(treatment = rbinom(1,1,0.5)))%>%
  rowwise() %>%
  mutate(educated = rbinom(1,1,0.3),
         u = sample(c(0.1,0.2,0.3),1),
         prob = 0.3 * treatment + 0.1 * educated + u,
         uses_fertilizer = rbinom(1,1,prob)) %>%
  ungroup() %>%
  select(-prob,-u) 

```

## Making a table of summary statistics


### Using Arsenal
The first table we make is a table of descriptive statistics
using the Arsenal package:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

library(arsenal)

descriptive_table <-
  data %>%
  select(where(is.numeric),-key_ID) %>%
  tableby(treatment ~ ., 
          data = .)

summary(descriptive_table)

```

That summary looks okay, even as raw text, and does what we want, so
let's export it to word! For this, we use Arsenal's `write2word()`
function. I had some trouble getting it to pick up my path, so I 
am using the [here library](https://here.r-lib.org/) to generate 
a path for me. This library is a must for shared projects!


```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

write2word(descriptive_table, here("tables/summ_stats_arsenal.docx"), title = "Descriptive Statistics", quiet = TRUE)

```

You can find the resulting .docx [here](https://github.com/kleuveld/r_cheatsheet/raw/main/tables/summ_stats_arsenal.docx).


### Using Flextable

For more control, the flextable package can covert data frames into good-looking table using the 
`tabulator()` function.

First, make a data frame with summarry statistics. I duplicate the data set using `bind_rows()`
to create an overall group.

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

summstats <-
bind_rows(data %>% mutate(Treatment = ifelse(treatment," Treatment","  Control")),
          data %>% mutate(Treatment = "Overall")) %>% 
  select(where(is.numeric),Treatment,-key_ID,-treatment) %>%
  group_by(Treatment) %>%
  summarize(across(everything(),
                     list(n =  ~sum(!is.na(.x)),
                          nmiss =  ~sum(is.na(.x)),
                          mean = ~mean(.x,na.rm=TRUE),
                          sd = ~sd(.x,na.rm=TRUE),
                          min =  ~min(.x,na.rm=TRUE),
                          max =  ~max(.x,na.rm=TRUE),
                          iqr =  ~IQR(.x,na.rm=TRUE)),
                      .names =  "{.col}-{.fn}")) %>%
  pivot_longer(cols = -Treatment,
                 names_to = c("Variable",".value"),
                 names_sep="-") 

summstats

```


Then use I flextable's `tabulator()` to make output that looks good in word. 
Note that `tabulator()` sorts the columns alphabetically, so that would be
control, overall, treatment. That doesn't make sense, so I have used spaces (`" Treatment"`) to 
control the ordering. 

I've added a bunch of statistics to show the flexibility:

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

library(flextable)

summstats %>%
tabulator(rows = "Variable",
          columns = "Treatment",
          `N` = as_paragraph(as_chunk(n,digits=0)),
          `Mean (SD)` =  as_paragraph(as_chunk(fmt_avg_dev(mean, sd, digit1=2,digit2 = 2))),
          Range = as_paragraph(as_chunk(min), "-",as_chunk(max)) ) %>%
as_flextable() 


```

To add a column with differences, I first define a [function](#functions) to compute the differences
(I use a regression rather than a ttest, so I can cluster my standard errors etc. to this if I need to). 
Then I use `summarize(across())` in much the same way as above, now to create a dataframe called `difcol`. 
Note that I use `.` to refer to the dataset currently in the `%>%` pipe.

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}


get_diffs <- function(.df,y,x){

  reg <-  lm(y~ x) %>% broom::tidy()

  coeff = round(reg[2,2],2)
  p <- reg[2,5]

  stars = case_when(p < 0.001 ~ "***",
                    p < 0.01 ~ "**",
                    p < 0.05 ~ "*",
                    .default = "" )

  paste0(coeff,stars)
}


difcol <-
  data %>%
  select(where(is.numeric),-key_ID,-treatment) %>%
  summarize(across(everything(),
                   .fns = function(x) get_diffs(.,.$x,data$treatment))) %>%
  pivot_longer(cols =everything(),
               names_to = "Variable",
               values_to="Difference")  


```

Then, all I have to do is add it to `tabulator()` using its `datasup_last` argument. Below, I also
use a few other flextable function to make the table nicer. In particular, `labelizor()` to add variable
labels, which I define as a vector.

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

#named vector with variable labels:
labels <- c("Household members","Years lived","Rooms","N. livestock owned","Meals per day", "Educated","Uses Ferilizer")
names(labels) <- summstats[[2]][1:7]


descriptive_table_flex <-
  summstats %>%
  tabulator(rows = "Variable",
            columns = "Treatment",
            datasup_last = difcol,
            `N` = as_paragraph(as_chunk(n,digits=0)),
            `Mean (SD)` =  as_paragraph(as_chunk(fmt_avg_dev(mean, sd, digit1=2,digit2 = 2)))) %>%
  as_flextable()  %>%
  labelizor(j = "Variable", labels = labels, part = "all") %>% 
  fix_border_issues() %>% 
  autofit()

descriptive_table_flex

```

To save it to word:

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

descriptive_table_flex %>%
  save_as_docx(path = here("tables/summs_stats_flex.docx"))

```


You can find the resulting .docx [here](https://github.com/kleuveld/r_cheatsheet/raw/main/tables/summs_stats_flex.docx).


### Using

## Simple regression

A simple regression uses the `lm()` function. We save the results
in an object, which we can later include in a table we export to word.

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

lm <- lm(uses_fertilizer ~ treatment + educated, data = data)
summary(lm)


```

## Robust standard errors

To get robust standard errors (bootstrapped) clustered at the village
level, we can use the following:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

library(lmtest)
library(sandwich)

lm_robust <- coeftest(lm, vcov = vcovBS(lm, cluster=~village))
lm_robust

```
<!-- alternatively: use lm_robust from estimatr -->


Let's also do a probit model:


```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=TRUE}

probit <- glm(uses_fertilizer ~ treatment + educated, 
                family = binomial(link = "probit"), 
                data = data)

summary(probit)

```

And get robust SEs:

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=TRUE}


probit_robust <- coeftest(probit, vcov = vcovBS(probit,cluster=~village))
probit_robust

```


## Exporting to word

To make a good looking regression table, I use the huxtable 
library. Note the use of `tidy_override()` to add statistics
to the model output.

To export the resulting tables to word, I use the huxtable package.
The package is extremely flexible, so check out [its website](https://cran.r-project.org/web/packages/huxtable/vignettes/huxreg.html).
Some of the flexibility is seen below, by adding the number of clusters
and formatting the number in the resulting table.

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

#add the number of clusers to each
lm_robust <- 
  huxtable::tidy_override(lm_robust,
                glance = list(n_clusters = 4),
                extend=TRUE)
probit_robust <- 
  huxtable::tidy_override(probit_robust,
                glance = list(n_clusters = 4),
                extend=TRUE)
#make the table
reg_table <-
  huxtable::huxreg("Linear" = lm,"Linear Robust" = lm_robust,
         "Probit" = probit, "Probit Robust" = probit_robust,
         statistics = c(N = "nobs",
                        Clusters = "n_clusters", 
                        "Adj. R2" = "adj.r.squared")) %>% 
  huxtable::set_number_format(row=9,value=0)

reg_table

```

That looks decent! However, huxtable doesn't work well with
Word. We can use `as_flextable()` to convert to flextable
(note that I had bad results with `flextable::as_flextable()`, so make
sure to use `huxtable::as_flextable()`), and then use flextable
to export to docx. 

```{r eval=TRUE,echo=TRUE,warning=TRUE,error=TRUE,message=FALSE}

reg_table %>%
  huxtable::as_flextable() %>%
  flextable::save_as_docx(path = here("tables/regression_table.docx"))

```

You can find there output [here](https://github.com/kleuveld/r_cheatsheet/raw/main/tables/regression_table.docx).

## modelsummary


### Descriptive statistics

```{r eval=TRUE, include = TRUE, echo=TRUE, warning=TRUE, error=TRUE, message=FALSE}

library(modelsummary)
library(tinytable)
library(flextable)

labels = c(no_membrs = "# HH Members",
           years_liv = "Year in village",
           rooms = "# Rooms",
           liv_count = "# Livestock",
           no_meals = "# Meals",
           treatment = "Treated",
           educated = "Educated",
           uses_fertilizer = "Uses fertilizer")

# descriptive stats
data %>%
select(where(is.numeric), -ends_with("ID")) %>%
datasummary(All(.) ~ Mean + SD + min + max + Histogram , data = ., output = "flextable") %>%
labelizor(j =1,labels = labels, part = "all")%>% 
  fix_border_issues() %>% 
  autofit()

treat_labels <- c("0" = "Control", "1" = "Treated")

# balance table
data %>%
select(where(is.numeric), -ends_with("ID")) %>%
datasummary_balance( ~ treatment , data = ., output = "flextable", start = TRUE, dinm = TRUE, dinm_statistic = "p.value") %>%
labelizor(j =1,labels = labels, part = "all")%>%
labelizor(labels = treat_labels, part = "header")%>% 
  fix_border_issues() %>% 
  autofit()


# regression table
library(estimatr)

lm <- lm(uses_fertilizer ~ treatment + educated, data = data)


lmrobust <- lm_robust(uses_fertilizer ~ treatment + educated, data = data, cluster = village, se_type = "stata")


# adding number of columns to glance output:
glance_custom.lm_robust <- function(x) {
  glance(x) %>%
  mutate(ncluster = x$nclusters)
}


# creating a map of statistics
stats_map <- tribble(
  ~raw,        ~clean,      ~fmt,
  "nobs",      "N",         0,
  "r.squared", "R Squared", 2,
  "adj.r.squared", "Adj. R Squared", 2,
  "ncluster","No. Clusters",0)

# creating the table
modelsummary(list("1" = lm, "2" = lmrobust),
            gof_map = stats_map,
            output = "flextable") %>%
autofit()



# now for a probit model

probit <- glm(uses_fertilizer ~ treatment + educated, 
                family = binomial(link = "probit"), 
                data = data)

# robust is a bit more diffuclt, lm_robust does not have a namesake.
# we can make one!
# some helper functions

glm_robust <- function(formula,family,data,cluster) {
  probit <- glm(formula, 
               family = family, 
                data = data)
  
  cluster_formula <- as.formula(paste0("~", cluster))

  model <- 
    coeftest(probit, vcov = vcovBS(probit,cluster=cluster_formula))

  attr(model,"nclusters") <- 
    data[row.names(model.frame(probit)),cluster] %>% unique() %>% nrow()

  model
}


tidy_custom.coeftest <- function(x){
  x[,] %>% as_tibble() %>%
  mutate(term = attr(x,"dimnames")[[1]]) %>%
  select(term,
         estimate = Estimate,
         std.error = `Std. Error`,
         statistic = `z value`,
         p.value = `Pr(>|z|)`) 
}

glance_custom.coeftest <- function(x){
  tibble(nobs = attr(x,"nobs"),
         logLik = as.numeric(attr(x,"logLik")),
        nclusters = attr(x,"nclusters")
        )
}




probitrobust <- glm_robust(uses_fertilizer ~ treatment + educated, family = binomial(link = "probit"), 
                data = data, cluster="village")

modelsummary(list("1" = probit, "2" = probitrobust),
             gof_map = c("nobs","n_clusters","logLik"),
            output = "flextable") %>%
autofit()

```