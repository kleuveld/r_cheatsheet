[["index.html", "R Cheat Sheet 1 About", " R Cheat Sheet Koen 2024-01-04 1 About This book contains some useful snippets for using R. Large parts of this cheat sheet are based on the materials for the R for Social Science Data Carpentry Workshop "],["setting-up.html", "2 Setting up", " 2 Setting up Before starting, we need some sample data, and make sure out data folder is set up properly. The file we’re using is a simple CSV file we download using he download.file() function. We will also download the packages we need. Especially tidyverse which contains a large number of functions to make data management easier. dir.create(&quot;data&quot;) download.file( &quot;https://raw.githubusercontent.com/datacarpentry/r-socialsci/main/episodes/data/SAFI_clean.csv&quot;, &quot;data/SAFI_clean.csv&quot;, mode = &quot;wb&quot; ) install.packages(c(&quot;tidyverse&quot;,&quot;here&quot;,&quot;arsenal&quot;,&quot;lmtest&quot;,&quot;sandwich&quot;,&quot;here&quot;, &quot;huxtable&quot;,&quot;flextable&quot;)) Then we load the file in R, using the read_csv() function from the tidyverse package library(tidyverse) interviews &lt;- read_csv(&quot;data/SAFI_clean.csv&quot;, na = &quot;NULL&quot;) "],["data-wrangling.html", "3 Data Wrangling 3.1 Basic Data Manipulation 3.2 Pivoting (or reshaping) 3.3 Joining (or merging) data 3.4 Summarizing over groups (or collapsing data) 3.5 Advanced Row Wise Operations", " 3 Data Wrangling 3.1 Basic Data Manipulation Below we do some basic data manipulations on our interview data. interviews %&gt;% filter(village == &quot;Chirodzo&quot;) %&gt;% mutate(people_per_room = no_membrs / rooms, day = day(interview_date), month = month(interview_date), year = year(interview_date)) %&gt;% select(key_ID:rooms, day:people_per_room, -village) %&gt;% filter(interview_date &gt; &quot;2016-12-1&quot; &amp; interview_date &lt; &#39;2017-01-01&#39;) ## # A tibble: 1 × 8 ## key_ID interview_date no_membrs years_liv respondent_wall_type rooms ## &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 10 2016-12-16 00:00:00 12 23 burntbricks 5 ## # ℹ 2 more variables: day &lt;int&gt;, people_per_room &lt;dbl&gt; Note: We filter a number of rows using the filter() function We create some new variables using mutate. Note that for some date operations we use the lubridate library, wich is include in the tidyverse. Check out lubridate’s documentation for more advanced date manipulation techniques. We select some of our variables using select(); note that you can select a range of variables using varaible1:variable2 and drop variables using the -. We “chain” all these operations together using the pipe operator %&gt;%. 3.2 Pivoting (or reshaping) When you want to combine two data frames at different levels of analysis, for example a household roster with the rest of the household questionnaire, you’ll run into the problem that the household roster has more rows than the household questionnaire: the household roster will have each row repeated for each household member (i.e. it is long data). To combine it with the household data data we need to make sure the columns are repeated for each member (ie make the data wide). In R, this is done using the pivot_wider() function, which works much like Stata’s reshape command. 3.2.1 Creating fake data First, let’s create some long data, so we have something to pivot. We will make sure that our household roster has a number of lines for each household that is equal to the household size, and has two randomly generated variables: female and age. long_data &lt;- interviews %&gt;% select(key_ID,no_membrs ) %&gt;% uncount(no_membrs) %&gt;% group_by(key_ID) %&gt;% mutate(member_ID = row_number()) %&gt;% rowwise() %&gt;% mutate(female = sample(0:1,1), age = case_when(member_ID == 1 ~ sample(18:86,1), .default = sample(0:86,1))) %&gt;% ungroup() long_data ## # A tibble: 942 × 4 ## key_ID member_ID female age ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 1 83 ## 2 1 2 0 57 ## 3 1 3 0 62 ## 4 2 1 1 58 ## 5 2 2 1 24 ## 6 2 3 0 19 ## 7 2 4 1 42 ## 8 2 5 0 48 ## 9 2 6 1 83 ## 10 2 7 1 19 ## # ℹ 932 more rows Note that this uses some advanced data wrangling: uncount() to inflate each number of rows by the number of members in the household. group_by(key_ID) and row_number() to generate the row number within all observations with the same key_ID. rowwise() to ensure randomizations are run over each row, rather than once for the entire data set. sample() to get random integers. case_when() to make sure the age is never lower than 18 if the member_id is 1 (presumably the household head). 3.2.2 Pivoting long to wide To merge this into our main data set, we need to make sure we go back to having 1 observation per household. We will do this by using pivot_wider(): wide_data &lt;- long_data %&gt;% pivot_wider(names_from = member_ID, values_from = !ends_with(&quot;_ID&quot;)) wide_data ## # A tibble: 131 × 39 ## key_ID female_1 female_2 female_3 female_4 female_5 female_6 female_7 ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 0 0 NA NA NA NA ## 2 2 1 1 0 1 0 1 1 ## 3 3 0 1 1 1 1 0 0 ## 4 4 0 1 0 1 0 0 1 ## 5 5 0 0 1 1 1 0 0 ## 6 6 1 0 0 NA NA NA NA ## 7 7 0 0 0 1 1 1 NA ## 8 8 1 1 1 1 1 1 1 ## 9 9 1 0 1 0 0 1 1 ## 10 10 0 0 1 1 0 1 0 ## # ℹ 121 more rows ## # ℹ 31 more variables: female_8 &lt;int&gt;, female_9 &lt;int&gt;, female_10 &lt;int&gt;, ## # female_11 &lt;int&gt;, female_12 &lt;int&gt;, female_13 &lt;int&gt;, female_14 &lt;int&gt;, ## # female_15 &lt;int&gt;, female_16 &lt;int&gt;, female_17 &lt;int&gt;, female_18 &lt;int&gt;, ## # female_19 &lt;int&gt;, age_1 &lt;int&gt;, age_2 &lt;int&gt;, age_3 &lt;int&gt;, age_4 &lt;int&gt;, ## # age_5 &lt;int&gt;, age_6 &lt;int&gt;, age_7 &lt;int&gt;, age_8 &lt;int&gt;, age_9 &lt;int&gt;, ## # age_10 &lt;int&gt;, age_11 &lt;int&gt;, age_12 &lt;int&gt;, age_13 &lt;int&gt;, age_14 &lt;int&gt;, … We only needed to specify two options: names_from: this is the column that contains the names (or usually numbers) for each of our units of analysis. In this case, the member_ID. values_from: the variables containing the data. All variables you specify here, will get one column for each possible value of names_from. In our case, these variables female and age. I used tidy select syntax to specify all variables except the ones ending in “_ID”. pivot_wider() will assume all variables not specified in names_from and values_from are the unique identifiers of your wide data. In our case, the only remaining variable is key_ID, which is indeed the unique identifier. 3.2.3 Pivoting wide to long If we had started with wide data, and had wanted to transform to long data, we’d have to use pivot_longer(): recreated_long_data &lt;- wide_data %&gt;% pivot_longer(!key_ID, names_to = c(&quot;.value&quot;, &quot;member_ID&quot;), names_sep=&quot;_&quot;, values_drop_na = TRUE) long_data ## # A tibble: 942 × 4 ## key_ID member_ID female age ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 1 83 ## 2 1 2 0 57 ## 3 1 3 0 62 ## 4 2 1 1 58 ## 5 2 2 1 24 ## 6 2 3 0 19 ## 7 2 4 1 42 ## 8 2 5 0 48 ## 9 2 6 1 83 ## 10 2 7 1 19 ## # ℹ 932 more rows In this case, the syntax is a bit harder to understand than that of pivot wider. It’s good to think first what the original data looks like, and how we intend to transform it. The wide data has columns key_ID, age_1-19 and female_1-19. We don’t really want to touch the key_ID column. We want to turn the columns age_1-19 and female_1-19 into three columns: female, age and Member_ID, which contains the values 1-19. This translates to the options we passed to pivot_longer() as follows: !key_ID: We want to pivot the data that’s in all columns except key_ID. names_to = c(\".value\", \"member_ID\"): this specifies the new columns we want to create. It basically says that the existing column names consist of two parts: one part (i.e. female and age) that we wish to keep as column names , and one part (i.e. the numbers 1-19) which should be put into a new column which we will “member_ID”. \"names_sep=\": this indicates how the two parts mentioned above are separated. If there is no separator (for example your variables are called age1, age2, etc.) you’ll have to use thenames_pattern option. values_drop_na = TRUE: tells R to drop rows that have missing data for all variables. If we had set this to FALSE, we’d have 19 rows for each household, with a lot of missing data in all households smaller than 19 people. 3.3 Joining (or merging) data Tidyverse has four functions to join (or merge, as Stata calls it) two data sets. The functions that differ in the way they treat observations that are in one data set but not the other. Consider the diagram below. It has two data sets, x (in Stata terms, this is the master data set) and y (the using data set in Stata terms). They have overlapping rows (area B), but also rows that are only in x (area A) or only in y (area C). The four join functions work as follows: inner_join() will only keep area B. left_join() will keep areas A and B. right_join() will keep areas B and C. full_join() will keep areas A, B, and C. In our case, the data sets match perfectly, i.e. we only have an area B, so there is no practical difference. I chose left_join() so the number of observations in my household survey is guaranteed to remain the same. To merge the roster to the household data, we use the join_by function: interviews %&gt;% left_join(wide_data) ## Joining with `by = join_by(key_ID)` ## # A tibble: 131 × 52 ## key_ID village interview_date no_membrs years_liv respondent_wall_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 God 2016-11-17 00:00:00 3 4 muddaub ## 2 2 God 2016-11-17 00:00:00 7 9 muddaub ## 3 3 God 2016-11-17 00:00:00 10 15 burntbricks ## 4 4 God 2016-11-17 00:00:00 7 6 burntbricks ## 5 5 God 2016-11-17 00:00:00 7 40 burntbricks ## 6 6 God 2016-11-17 00:00:00 3 3 muddaub ## 7 7 God 2016-11-17 00:00:00 6 38 muddaub ## 8 8 Chirodzo 2016-11-16 00:00:00 12 70 burntbricks ## 9 9 Chirodzo 2016-11-16 00:00:00 8 6 burntbricks ## 10 10 Chirodzo 2016-12-16 00:00:00 12 23 burntbricks ## # ℹ 121 more rows ## # ℹ 46 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;, ## # liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;, ## # instanceID &lt;chr&gt;, female_1 &lt;int&gt;, female_2 &lt;int&gt;, female_3 &lt;int&gt;, ## # female_4 &lt;int&gt;, female_5 &lt;int&gt;, female_6 &lt;int&gt;, female_7 &lt;int&gt;, ## # female_8 &lt;int&gt;, female_9 &lt;int&gt;, female_10 &lt;int&gt;, female_11 &lt;int&gt;, ## # female_12 &lt;int&gt;, female_13 &lt;int&gt;, female_14 &lt;int&gt;, female_15 &lt;int&gt;, … Note that we didn’t specify identifiers, like we would in Stata. R assumed that the variables that appear in both data frames are the identifiers, in this case key_ID. Use the by option to change this. Going the other way around, joining the household data to the roster data, is equally easy: long_data %&gt;% left_join( interviews %&gt;% select(key_ID,village,interview_date)) ## Joining with `by = join_by(key_ID)` ## # A tibble: 942 × 6 ## key_ID member_ID female age village interview_date ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dttm&gt; ## 1 1 1 1 83 God 2016-11-17 00:00:00 ## 2 1 2 0 57 God 2016-11-17 00:00:00 ## 3 1 3 0 62 God 2016-11-17 00:00:00 ## 4 2 1 1 58 God 2016-11-17 00:00:00 ## 5 2 2 1 24 God 2016-11-17 00:00:00 ## 6 2 3 0 19 God 2016-11-17 00:00:00 ## 7 2 4 1 42 God 2016-11-17 00:00:00 ## 8 2 5 0 48 God 2016-11-17 00:00:00 ## 9 2 6 1 83 God 2016-11-17 00:00:00 ## 10 2 7 1 19 God 2016-11-17 00:00:00 ## # ℹ 932 more rows Note that here I only merged in two variables, by using select and a pipe within the left_join() function. 3.4 Summarizing over groups (or collapsing data) To compute summary statistics (sums, counts, means etc.) over a group, we use the group_by() and summarize() functions. For example, to compute the household size, number of women and average age in each household: long_data %&gt;% group_by(key_ID) %&gt;% summarize(hh_size = n(), num_women = sum(female), mean_age = mean(age)) ## # A tibble: 131 × 4 ## key_ID hh_size num_women mean_age ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 3 1 67.3 ## 2 2 7 5 41.9 ## 3 3 10 6 32.4 ## 4 4 7 3 44.6 ## 5 5 7 3 33.9 ## 6 6 3 1 33.3 ## 7 7 6 3 29.7 ## 8 8 12 8 45.2 ## 9 9 8 4 39.4 ## 10 10 12 7 32.1 ## # ℹ 121 more rows 3.5 Advanced Row Wise Operations Suppose we wanted to get the above information (the household size, number of women and average age in each) from the wide data. The easiest, and probably best, way to do this in R is by reshaping to long, and do the above. But in Stata you would probably use some sort of egen function, and you can do similar things in R. It’s just a bit more complex: wide_data %&gt;% rowwise() %&gt;% mutate(mean_age = mean(c_across(starts_with(&quot;age_&quot;)), na.rm=TRUE), num_women = sum(c_across(starts_with(&quot;female_&quot;)), na.rm=TRUE), hh_size = sum(!is.na(c_across(starts_with(&quot;female_&quot;))), na.rm=TRUE)) %&gt;% select(key_ID,hh_size,num_women,mean_age) %&gt;% ungroup() ## # A tibble: 131 × 4 ## key_ID hh_size num_women mean_age ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 3 1 67.3 ## 2 2 7 5 41.9 ## 3 3 10 6 32.4 ## 4 4 7 3 44.6 ## 5 5 7 3 33.9 ## 6 6 3 1 33.3 ## 7 7 6 3 29.7 ## 8 8 12 8 45.2 ## 9 9 8 4 39.4 ## 10 10 12 7 32.1 ## # ℹ 121 more rows The key trick here is the combination of rowwise() and c_across(). rowwise() ensure all summaries are computed per row, and c_across() allows you to use tidy select syntax within the mean() and sum() functions. sum(!is.na()) simply counts the non-missing values. "],["estimating-and-reporting.html", "4 Estimating and reporting 4.1 Generating some fake data 4.2 Making a table of summary statistics 4.3 Simple regression 4.4 Robust standard errors 4.5 Exporting to word", " 4 Estimating and reporting This chapter uses a large number of packages, so make sure all are installed by running the code from the first chapter. I will create a table of descriptive statistics, and a simple regression table. 4.1 Generating some fake data First we make a fake intervention aimed at improving fertilizer adoption. Adoption depends on the treatment and education and a random component. library(tidyverse) rm(list=ls()) set.seed(1) data &lt;- read_csv(&quot;data/SAFI_clean.csv&quot;, na = &quot;NULL&quot;) %&gt;% left_join({.} %&gt;% select(village) %&gt;% distinct(village) %&gt;% rowwise %&gt;% mutate(treatment = rbinom(1,1,0.5)))%&gt;% rowwise() %&gt;% mutate(educated = rbinom(1,1,0.3), u = sample(c(0.1,0.2,0.3),1), prob = 0.3 * treatment + 0.1 * educated + u, uses_fertilizer = rbinom(1,1,prob)) %&gt;% select(-prob,-u) ## Rows: 131 Columns: 14 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (7): village, respondent_wall_type, memb_assoc, affect_conflicts, items... ## dbl (6): key_ID, no_membrs, years_liv, rooms, liv_count, no_meals ## dttm (1): interview_date ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## Joining with `by = join_by(village)` 4.2 Making a table of summary statistics The first table we make is a table of descriptive statistics using the Arsenal package: library(arsenal) descriptive_table &lt;- data %&gt;% select(where(is.numeric),-key_ID) %&gt;% tableby(treatment ~ ., data = .) summary(descriptive_table) ## ## ## | | 0 (N=82) | 1 (N=49) | Total (N=131) | p value| ## |:---------------------------|:---------------:|:---------------:|:---------------:|-------:| ## |**no_membrs** | | | | 0.290| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 6.963 (2.856) | 7.571 (3.640) | 7.191 (3.172) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 2.000 - 15.000 | 2.000 - 19.000 | 2.000 - 19.000 | | ## |**years_liv** | | | | 0.331| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 21.939 (14.921) | 24.918 (19.832) | 23.053 (16.913) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 1.000 - 70.000 | 2.000 - 96.000 | 1.000 - 96.000 | | ## |**rooms** | | | | 0.963| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 1.744 (1.174) | 1.735 (0.953) | 1.740 (1.093) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 1.000 - 8.000 | 1.000 - 4.000 | 1.000 - 8.000 | | ## |**liv_count** | | | | 0.094| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 2.244 (1.013) | 2.571 (1.173) | 2.366 (1.083) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 1.000 - 4.000 | 1.000 - 5.000 | 1.000 - 5.000 | | ## |**no_meals** | | | | 0.596| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 2.585 (0.496) | 2.633 (0.487) | 2.603 (0.491) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 2.000 - 3.000 | 2.000 - 3.000 | 2.000 - 3.000 | | ## |**educated** | | | | 0.872| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 0.293 (0.458) | 0.306 (0.466) | 0.298 (0.459) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 0.000 - 1.000 | 0.000 - 1.000 | 0.000 - 1.000 | | ## |**uses_fertilizer** | | | | 0.002| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 0.244 (0.432) | 0.510 (0.505) | 0.344 (0.477) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 0.000 - 1.000 | 0.000 - 1.000 | 0.000 - 1.000 | | That summary looks okay, even as raw text, and does what we want, so let’s export it to word! For this, we use Arsenal’s write2word() function. I had some trouble getting it to pick up my path, so I am using the here library to generate a path for me. This library is a must for shared projects! here::i_am(&quot;README.md&quot;) library(here) write2word(descriptive_table, here(&quot;tables/summ_stats.docx&quot;), title = &quot;Descriptive Statistics&quot;, quiet = TRUE) 4.3 Simple regression A simple regression uses the lm() function. We save the results in an object, which we can later include in a table we export to word. lm &lt;- lm(uses_fertilizer ~ treatment + educated, data = data) summary(lm) ## ## Call: ## lm(formula = uses_fertilizer ~ treatment + educated, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.5987 -0.3341 -0.2066 0.5289 0.7934 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.20657 0.05677 3.639 0.000396 *** ## treatment 0.26459 0.08282 3.195 0.001762 ** ## educated 0.12757 0.08764 1.456 0.147949 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4586 on 128 degrees of freedom ## Multiple R-squared: 0.08871, Adjusted R-squared: 0.07447 ## F-statistic: 6.23 on 2 and 128 DF, p-value: 0.002618 4.4 Robust standard errors To get robust standard errors (bootstrapped) clustered at the village level, we can use the following: library(lmtest) library(sandwich) lm_robust &lt;- coeftest(lm, vcov = vcovBS(lm, cluster=~village)) lm_robust ## ## t test of coefficients: ## ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.206566 0.076970 2.6837 0.008244 ** ## treatment 0.264587 0.103139 2.5653 0.011460 * ## educated 0.127568 0.072263 1.7653 0.079895 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Let’s also do a probit model: probit &lt;- glm(uses_fertilizer ~ treatment + educated, family = binomial(link = &quot;probit&quot;), data = data) summary(probit) ## ## Call: ## glm(formula = uses_fertilizer ~ treatment + educated, family = binomial(link = &quot;probit&quot;), ## data = data) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.8129 0.1731 -4.697 2.64e-06 *** ## treatment 0.7268 0.2359 3.081 0.00206 ** ## educated 0.3664 0.2499 1.467 0.14251 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 168.55 on 130 degrees of freedom ## Residual deviance: 156.85 on 128 degrees of freedom ## AIC: 162.85 ## ## Number of Fisher Scoring iterations: 4 And get robust SEs: probit_robust &lt;- coeftest(probit, vcov = vcovBS(probit,cluster=~village)) probit_robust ## ## z test of coefficients: ## ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.81293 0.27529 -2.9529 0.003148 ** ## treatment 0.72679 0.28738 2.5291 0.011436 * ## educated 0.36643 0.22746 1.6110 0.107179 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.5 Exporting to word To make a good looking regression table, I use the huxtable library. Note the use of tidy_override() to add statistics to the model output. To export the resulting tables to word, I use the huxtable package. The package is extremely flexible, so check out its website. Some of the flexibility is seen below, by adding the number of clusters and formatting the number in the resulting table. library(huxtable) #add the number of clusers to each lm_robust &lt;- tidy_override(lm_robust, glance = list(n_clusters = 4), extend=TRUE) probit_robust &lt;- tidy_override(probit_robust, glance = list(n_clusters = 4), extend=TRUE) #make the table reg_table &lt;- huxreg(&quot;Linear&quot; = lm,&quot;Linear Robust&quot; = lm_robust, &quot;Probit&quot; = probit, &quot;Probit Robust&quot; = probit_robust, statistics = c(N = &quot;nobs&quot;, Clusters = &quot;n_clusters&quot;, &quot;Adj. R2&quot; = &quot;adj.r.squared&quot;)) %&gt;% set_number_format(row=9,value=0) reg_table Table 4.1: LinearLinear RobustProbitProbit Robust (Intercept)0.207 ***0.207 **-0.813 ***-0.813 ** (0.057)&nbsp;&nbsp;&nbsp;(0.077)&nbsp;&nbsp;(0.173)&nbsp;&nbsp;&nbsp;(0.275)&nbsp;&nbsp; treatment0.265 **&nbsp;0.265 *&nbsp;0.727 **&nbsp;0.727 *&nbsp; (0.083)&nbsp;&nbsp;&nbsp;(0.103)&nbsp;&nbsp;(0.236)&nbsp;&nbsp;&nbsp;(0.287)&nbsp;&nbsp; educated0.128&nbsp;&nbsp;&nbsp;&nbsp;0.128&nbsp;&nbsp;&nbsp;0.366&nbsp;&nbsp;&nbsp;&nbsp;0.366&nbsp;&nbsp;&nbsp; (0.088)&nbsp;&nbsp;&nbsp;(0.072)&nbsp;&nbsp;(0.250)&nbsp;&nbsp;&nbsp;(0.227)&nbsp;&nbsp; N131&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;131&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;131&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;131&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Clusters&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Adj. R20.074&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05. That looks decent! However, huxtable doesn’t work well with Word. We can use as_flextable() to convert to flextable (note that I had bad results with flextable::as_flextable(), so make sure to use huxtable::as_flextable()), and then use flextable to export to docx. library(flextable) reg_table %&gt;% huxtable::as_flextable() %&gt;% flextable::save_as_docx(path = here(&quot;tables/regression_table.docx&quot;)) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
